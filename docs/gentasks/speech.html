<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title> | AI Dev Kit </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content=" | AI Dev Kit ">
      
      
      <link rel="icon" href="../../favicon.ico">
      <link rel="stylesheet" href="../../public/docfx.min.css">
      <link rel="stylesheet" href="../../public/main.css">
      <meta name="docfx:navrel" content="../../toc.html">
      <meta name="docfx:tocrel" content="../toc.html">
      
      <meta name="docfx:rel" content="../../">
      
      
      <meta name="docfx:docurl" content="https://github.com/Glitch9Inc/AIDevKit/blob/main/docs/gentasks/speech.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../../index.html">
            <img id="logo" class="svg" src="../../images/logo.png" alt="AI Dev Kit">
            AI Dev Kit
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">

<p><strong>Text-to-Speech (GENSpeechTask):</strong> You can create a speech synthesis task from a string using <code>.GENSpeech()</code>. For example:</p>
<pre><code class="lang-csharp">&quot;Hello, world!&quot;.GENSpeech()
    .SetVoice(ElevenLabsVoice.Rachel)   // choose a voice (e.g., a preset from ElevenLabs)
    .ExecuteAsync();
</code></pre>
<p>This will send the text to a TTS model and produce an audio clip (the <code>GeneratedAudio</code>). If you call <code>.GENSpeech()</code> on an <code>AudioSource</code> component instead of a string, the resulting audio clip will be automatically assigned to that AudioSource. For instance:</p>
<pre><code class="lang-csharp">myAudioSource.GENSpeech(&quot;Welcome to our game!&quot;)
    .SetVoice(ElevenLabsVoice.Rachel)
    .ExecuteAsync();
// After completion, myAudioSource.clip is set to the generated speech audio.
</code></pre>
<p>Now that the AudioSource has the clip, you can play it in-game. In this example, you might want to call <code>myAudioSource.Play()</code> after the task finishes to actually hear it. If using an async method, you could <code>await</code> the <code>ExecuteAsync()</code> call, then call <code>Play()</code> on the next line. Alternatively, as we'll see in the streaming section, you could use a callback to play automatically when done.</p>
<p><strong>Choosing a Voice:</strong> The <code>.SetVoice(...)</code> method on GENSpeechTask lets you pick a specific voice preset for TTS. The Dev Kit likely includes predefined voices (for example, <code>ElevenLabsVoice.Rachel</code> as used above, or other providers' voices). If not set, a default voice may be used. You might also have methods like <code>.SetSpeed(float)</code> to control playback speed of the voice or <code>.SetSeed(uint)</code> for reproducibility, depending on the AI provider capabilities.</p>
<p><strong>Speech-to-Text (GENTranscriptTask):</strong> To transcribe an <code>AudioClip</code> (e.g., microphone recording) to text, use <code>.GENTranscript()</code> on the AudioClip. For example:</p>
<pre><code class="lang-csharp">audioClip.GENTranscript()
    .ExecuteAsync();
</code></pre>
<p>This will produce a <code>GeneratedText</code> result with the transcription of the audio (often using models like OpenAI's Whisper for speech recognition). If you have a UI text element where you want the transcription to appear, you can call <code>.GENTranscript()</code> on that text element and pass the clip as a parameter:</p>
<pre><code class="lang-csharp">myTranscriptTextUI.GENTranscript(myRecordedClip)
    .ExecuteAsync();
</code></pre>
<p>Because we started from <code>myTranscriptTextUI</code> (a <code>Text</code> or TMP text), once the transcription is done, the resulting text will automatically be set on that UI element (so the spoken words appear as on-screen text).</p>
<p>There is also an optional <code>.SetLanguage()</code> for GENTranscriptTask if you want to hint the language of the audio for better accuracy (if not English). For example: <code>audioClip.GENTranscript().SetLanguage(SystemLanguage.French).ExecuteAsync();</code>.</p>
<p><strong>Other audio tasks:</strong> They work similarly:</p>
<ul>
<li>To generate a <strong>sound effect</strong> from text: <code>&quot;Footsteps on snow&quot;.GENSoundEffect().ExecuteAsync();</code> (this returns an AudioClip; you can target an AudioSource similarly with <code>.GENSoundEffect()</code> on the AudioSource).</li>
<li>To <strong>change the voice</strong> in a clip: <code>myClip.GENVoiceChange().SetVoice(ElevenLabsVoice.Antoni).ExecuteAsync();</code> (this might use an AI voice transformation model; target an AudioSource to apply the new voice clip to it).</li>
<li>To <strong>isolate audio</strong> elements: <code>myClip.GENAudioIsolation().ExecuteAsync();</code> (e.g., returns an AudioClip of isolated vocals or removed vocals, depending on default settings).</li>
</ul>
<p>Keep in mind some of these specialized tasks may require specific AI providers (for example, the ElevenLabs API for certain voice cloning or sound generation features). If you attempt to use them without the appropriate model or API configured, you might get a &quot;Not supported&quot; error. Always ensure you have set a suitable model via <code>SetModel</code> or that your default provider supports the task.</p>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/Glitch9Inc/AIDevKit/blob/main/docs/gentasks/speech.md/#L1" class="edit-link">Edit this page</a>
        </div>

        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          <span>Made with <a href="https://dotnet.github.io/docfx">docfx</a></span>
        </div>
      </div>
    </footer>
  </body>
</html>
